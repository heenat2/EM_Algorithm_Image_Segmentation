{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 12419 746316\n",
      "data initialization done\n"
     ]
    }
   ],
   "source": [
    "from scipy.misc import logsumexp\n",
    "import numpy as np\n",
    "\n",
    "# Read docword.nips.txt and initialize document count, vocan size and total words.\n",
    "# data_dv is an array of word counts with doc_count rows and vocab_size columns\n",
    "# data_vd is an array of word counts with vocab_size rows and doc_count columns\n",
    "\n",
    "with open('docword.nips.txt','r') as f:\n",
    "    doc_count = int(f.readline().strip())\n",
    "    vocab_size = int(f.readline().strip())\n",
    "    total_words = int(f.readline().strip())\n",
    "    print(doc_count,vocab_size,total_words)\n",
    "    data_dv = np.zeros((doc_count,vocab_size),dtype=int)\n",
    "    for line in f:\n",
    "        [docid,wordid,count] = [int(i) for i in line.strip().split()]\n",
    "        data_dv[docid-1][wordid-1] = count\n",
    "data_vd = np.transpose(data_dv)\n",
    "print('data initialization done')\n",
    "\n",
    "# initialize previous wij matrix to compute difference over successive runs later on\n",
    "\n",
    "prev_wij = np.zeros((1500,30))\n",
    "first = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# create a random list of cluster numbers for each of the 1500 documents\n",
    "\n",
    "random_clusters = random.choices(population=range(0,30), k=1500)\n",
    "\n",
    "# initialize values for pi_j as 'number of  docs in cluster j'/'total number of docs' and compute its log\n",
    "\n",
    "pi = []\n",
    "topic_count = 30\n",
    "for i in range(0,topic_count):\n",
    "    pi.append(random_clusters.count(i)/doc_count)\n",
    "pi[0] = pi[0] + (1-sum(pi))\n",
    "pi = np.log(pi)\n",
    "\n",
    "# initialize topic probability matrix\n",
    "\n",
    "topic_p = np.zeros((topic_count,vocab_size))\n",
    "for i in range(0,doc_count):\n",
    "    #sum up count of words in each cluster\n",
    "    topic_p[random_clusters[i]] += data_dv[i]\n",
    "topic_p = np.transpose(topic_p)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# perform EM until matrix wij converges to 1e-8\n",
    "\n",
    "while(wij_diff > 1e-8 or first == 1):\n",
    "    first = 0\n",
    "    # perform smoothing to ensure no word probability in a topic is 0\n",
    "    for i in range(0,topic_count):\n",
    "        topic_p[:,i] = np.log((topic_p[:,i] + 0.2)/(sum(topic_p[:,i]) + vocab_size*0.2))\n",
    "    log_wij_num = np.dot(data_dv,topic_p) + pi\n",
    "    log_wij_den = np.apply_along_axis(logsumexp,1,log_wij_num).reshape(1500,1)\n",
    "    log_wij = log_wij_num - log_wij_den\n",
    "    wij = np.exp(log_wij)\n",
    "    wij_diff = np.amax(np.absolute(wij - prev_wij))\n",
    "    #print(wij_diff)\n",
    "    prev_wij = wij\n",
    "    new_topic_p_num = np.dot(data_vd,wij)\n",
    "    new_topic_p_den = np.apply_along_axis(sum,0,new_topic_p_num).reshape(1,30)\n",
    "    new_topic_p = new_topic_p_num/new_topic_p_den\n",
    "    topic_p = new_topic_p\n",
    "    new_pi = np.log(np.apply_along_axis(sum,0,wij)/1500)\n",
    "    pi = new_pi\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(sum(np.exp(pi)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# graph of pi values of topics\n",
    "\n",
    "f = plt.figure()\n",
    "plt.bar(range(1,31),np.exp(pi))\n",
    "plt.xlabel(\"Topic Number\")\n",
    "plt.ylabel(\"Probability of Selection\")\n",
    "plt.savefig('hw1graph.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read file vocab.nips.txt into a list\n",
    "\n",
    "vocab = []\n",
    "with open('vocab.nips.txt','r') as vocabfl:\n",
    "    for line in vocabfl:\n",
    "        vocab.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_p = np.transpose(topic_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "model signal sound auditory frequency system filter output input analog \n",
      "\n",
      "noise signal system neural information neuron input model analog network \n",
      "\n",
      "function set kernel vector data algorithm training problem svm support \n",
      "\n",
      "network unit input learning weight function output neural training hidden \n",
      "\n",
      "distance tangent set transformation vector algorithm model point learning pattern \n",
      "\n",
      "model orientation cortical ocular map dominance input cell pattern visual \n",
      "\n",
      "algorithm function learning problem vector set result error network weight \n",
      "\n",
      "point manifold space model set data image dimensional learning algorithm \n",
      "\n",
      "image images model point algorithm system map scene sensor color \n",
      "\n",
      "circuit current chip input voltage output analog system neural network \n",
      "\n",
      "bat target delay echoes echo glint image simmon range neural \n",
      "\n",
      "function entropy filter gaussian wavelet approximation distribution density component basis \n",
      "\n",
      "cell model input neuron visual field direction system response network \n",
      "\n",
      "word character network recognition training system set input neural model \n",
      "\n",
      "face images image network recognition set system facial representation faces \n",
      "\n",
      "target cues cue search model visual location display feature system \n",
      "\n",
      "speech network system recognition training model hmm neural set speaker \n",
      "\n",
      "input map network task output pattern unit learning system feature \n",
      "\n",
      "object model view network visual unit recognition image representation features \n",
      "\n",
      "learning function action algorithm policy system problem optimal reinforcement model \n",
      "\n",
      "data algorithm model set cluster clustering learning function point problem \n",
      "\n",
      "model data parameter network set algorithm learning function neural number \n",
      "\n",
      "motion direction visual model unit field system network velocity cell \n",
      "\n",
      "model learning control system movement network motor dynamic forward controller \n",
      "\n",
      "neuron network model input neural synaptic function spike firing system \n",
      "\n",
      "training error network set learning function data input weight neural \n",
      "\n",
      "network neural input function system learning training set output weight \n",
      "\n",
      "region texture iiii model depth contrast image frequency local visual \n",
      "\n",
      "mean field distribution network model gaussian approximation function algorithm learning \n",
      "\n",
      "component signal eeg independent data algorithm artifact ica sources information "
     ]
    }
   ],
   "source": [
    "# print words corresponding to top 10 probabilities for each topic\n",
    "\n",
    "for i in range(0,topic_count):\n",
    "    print('\\n')\n",
    "    indices = topic_p[i].argsort()[-10:][::-1]\n",
    "    for j in indices:\n",
    "        print(vocab[j]+ ' ',end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
